{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install GPUtil  ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:38:29.787464Z","iopub.execute_input":"2023-09-30T17:38:29.788125Z","iopub.status.idle":"2023-09-30T17:38:41.367893Z","shell.execute_reply.started":"2023-09-30T17:38:29.788091Z","shell.execute_reply":"2023-09-30T17:38:41.366767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pandas==1.5.3\n!pip install transformers\n!pip install datasets==2.11\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:38:41.370003Z","iopub.execute_input":"2023-09-30T17:38:41.370885Z","iopub.status.idle":"2023-09-30T17:39:24.893886Z","shell.execute_reply.started":"2023-09-30T17:38:41.370845Z","shell.execute_reply":"2023-09-30T17:39:24.892748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport wandb\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:46:23.931044Z","iopub.execute_input":"2023-09-30T17:46:23.931379Z","iopub.status.idle":"2023-09-30T17:46:23.936641Z","shell.execute_reply.started":"2023-09-30T17:46:23.931353Z","shell.execute_reply":"2023-09-30T17:46:23.935754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/processed-taylorswift-df/processed_df.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:37.482046Z","iopub.execute_input":"2023-09-30T17:39:37.484650Z","iopub.status.idle":"2023-09-30T17:39:37.541489Z","shell.execute_reply.started":"2023-09-30T17:39:37.484616Z","shell.execute_reply":"2023-09-30T17:39:37.540514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = load_dataset(\"csv\", data_files=\"/kaggle/input/processed-taylorswift-df/processed_df.csv\", split = \"train\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:37.546859Z","iopub.execute_input":"2023-09-30T17:39:37.549026Z","iopub.status.idle":"2023-09-30T17:39:38.241131Z","shell.execute_reply.started":"2023-09-30T17:39:37.548992Z","shell.execute_reply":"2023-09-30T17:39:38.240326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:38.242521Z","iopub.execute_input":"2023-09-30T17:39:38.243118Z","iopub.status.idle":"2023-09-30T17:39:38.252577Z","shell.execute_reply.started":"2023-09-30T17:39:38.243087Z","shell.execute_reply":"2023-09-30T17:39:38.251813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train dataset size: {len(ds)}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:38.254182Z","iopub.execute_input":"2023-09-30T17:39:38.254834Z","iopub.status.idle":"2023-09-30T17:39:38.263627Z","shell.execute_reply.started":"2023-09-30T17:39:38.254805Z","shell.execute_reply":"2023-09-30T17:39:38.262786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"TRAINING SAMPLE: \\n{ds['lyrics'][0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:38.265077Z","iopub.execute_input":"2023-09-30T17:39:38.265847Z","iopub.status.idle":"2023-09-30T17:39:38.279253Z","shell.execute_reply.started":"2023-09-30T17:39:38.265791Z","shell.execute_reply":"2023-09-30T17:39:38.278200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenize the text \n\nmodel_id=\"gpt2\"\n\n# Load tokenizer of FLAN-t5-base\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:38.284340Z","iopub.execute_input":"2023-09-30T17:39:38.284916Z","iopub.status.idle":"2023-09-30T17:39:40.631581Z","shell.execute_reply.started":"2023-09-30T17:39:38.284879Z","shell.execute_reply":"2023-09-30T17:39:40.630615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test tokenizer\n\ntokenizer(ds[\"lyrics\"][0])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:40.633018Z","iopub.execute_input":"2023-09-30T17:39:40.633594Z","iopub.status.idle":"2023-09-30T17:39:40.653851Z","shell.execute_reply.started":"2023-09-30T17:39:40.633546Z","shell.execute_reply":"2023-09-30T17:39:40.652884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:40.656929Z","iopub.execute_input":"2023-09-30T17:39:40.657726Z","iopub.status.idle":"2023-09-30T17:39:40.663438Z","shell.execute_reply.started":"2023-09-30T17:39:40.657696Z","shell.execute_reply":"2023-09-30T17:39:40.662550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntokenizer.pad_token = tokenizer.eos_token\ntokenized_dataset = ds.map(lambda x: tokenizer(x[\"lyrics\"], truncation = True, padding = True), batched=True, remove_columns =[\"Tracks\",\"Album_ID\", \"Album\", \"Album_Path\"])\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\ntokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:46:27.706904Z","iopub.execute_input":"2023-09-30T17:46:27.707237Z","iopub.status.idle":"2023-09-30T17:46:27.741192Z","shell.execute_reply.started":"2023-09-30T17:46:27.707208Z","shell.execute_reply":"2023-09-30T17:46:27.740018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset.format","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:41.643357Z","iopub.execute_input":"2023-09-30T17:39:41.644320Z","iopub.status.idle":"2023-09-30T17:39:41.650950Z","shell.execute_reply.started":"2023-09-30T17:39:41.644287Z","shell.execute_reply":"2023-09-30T17:39:41.649884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the dataset\ntokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:47:36.075513Z","iopub.execute_input":"2023-09-30T17:47:36.076190Z","iopub.status.idle":"2023-09-30T17:47:36.089890Z","shell.execute_reply.started":"2023-09-30T17:47:36.076159Z","shell.execute_reply":"2023-09-30T17:47:36.088966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:47:37.061285Z","iopub.execute_input":"2023-09-30T17:47:37.061657Z","iopub.status.idle":"2023-09-30T17:47:37.068057Z","shell.execute_reply.started":"2023-09-30T17:47:37.061628Z","shell.execute_reply":"2023-09-30T17:47:37.066555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset[\"train\"][\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:42:37.550531Z","iopub.execute_input":"2023-09-30T17:42:37.550889Z","iopub.status.idle":"2023-09-30T17:42:37.569010Z","shell.execute_reply.started":"2023-09-30T17:42:37.550862Z","shell.execute_reply":"2023-09-30T17:42:37.568148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:41.695056Z","iopub.execute_input":"2023-09-30T17:39:41.695943Z","iopub.status.idle":"2023-09-30T17:39:45.975424Z","shell.execute_reply.started":"2023-09-30T17:39:41.695914Z","shell.execute_reply":"2023-09-30T17:39:45.974582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:45.977043Z","iopub.execute_input":"2023-09-30T17:39:45.977394Z","iopub.status.idle":"2023-09-30T17:39:47.428089Z","shell.execute_reply.started":"2023-09-30T17:39:45.977353Z","shell.execute_reply":"2023-09-30T17:39:47.427182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define wandb variables\nwandb.login()\n\nos.environ[\"WANDB_PROJECT\"] = \"song-generator\" # log to your project ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:39:51.455018Z","iopub.execute_input":"2023-09-30T17:39:51.455585Z","iopub.status.idle":"2023-09-30T17:41:27.844772Z","shell.execute_reply.started":"2023-09-30T17:39:51.455537Z","shell.execute_reply":"2023-09-30T17:41:27.843840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env WANDB_LOG_MODEL=true","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:32:39.666909Z","iopub.execute_input":"2023-09-30T17:32:39.667241Z","iopub.status.idle":"2023-09-30T17:32:39.677739Z","shell.execute_reply.started":"2023-09-30T17:32:39.667215Z","shell.execute_reply":"2023-09-30T17:32:39.676888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check GPU usage\nfrom GPUtil import showUtilization as gpu_usage\ngpu_usage()  ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:38:06.303713Z","iopub.execute_input":"2023-09-30T17:38:06.304175Z","iopub.status.idle":"2023-09-30T17:38:06.331708Z","shell.execute_reply.started":"2023-09-30T17:38:06.304142Z","shell.execute_reply":"2023-09-30T17:38:06.330705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:17:05.056459Z","iopub.execute_input":"2023-09-30T18:17:05.056803Z","iopub.status.idle":"2023-09-30T18:17:05.062827Z","shell.execute_reply.started":"2023-09-30T18:17:05.056777Z","shell.execute_reply":"2023-09-30T18:17:05.061726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train GPT2\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/finetuned_gpt2\",\n    evaluation_strategy=\"epoch\",\n    \n    save_strategy=\"no\",\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    logging_steps = 250,\n    num_train_epochs = 10,\n    per_device_train_batch_size = 4,\n    report_to=\"wandb\",\n    run_name = \"baseline_gpt2_finetune\",\n    load_best_model_at_end = True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator = data_collator,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T17:47:43.204975Z","iopub.execute_input":"2023-09-30T17:47:43.205309Z","iopub.status.idle":"2023-09-30T17:56:10.513293Z","shell.execute_reply.started":"2023-09-30T17:47:43.205283Z","shell.execute_reply":"2023-09-30T17:56:10.512034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:28:45.182606Z","iopub.execute_input":"2023-09-30T18:28:45.183036Z","iopub.status.idle":"2023-09-30T18:28:46.270803Z","shell.execute_reply.started":"2023-09-30T18:28:45.183004Z","shell.execute_reply":"2023-09-30T18:28:46.269629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"/kaggle/working/finetuned_gpt2\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:30:56.769693Z","iopub.execute_input":"2023-09-30T18:30:56.770044Z","iopub.status.idle":"2023-09-30T18:30:56.925342Z","shell.execute_reply.started":"2023-09-30T18:30:56.770021Z","shell.execute_reply":"2023-09-30T18:30:56.924099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base\ntest_prompt = \"End of passion play, crumbling away\\nI'm your source of self-destruction\\nVeins that pump with fear, sucking darkest clear\"","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:54:39.593096Z","iopub.execute_input":"2023-09-30T18:54:39.593456Z","iopub.status.idle":"2023-09-30T18:54:39.601380Z","shell.execute_reply.started":"2023-09-30T18:54:39.593430Z","shell.execute_reply":"2023-09-30T18:54:39.600498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = pipeline('text-generation', model= model_id, device=\"cuda:0\")\n\n#Generate text and show results\nresult = model(test_prompt, penalty_alpha=0.7, top_k=5, max_new_tokens=300)\n\nprint(result[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:54:42.223985Z","iopub.execute_input":"2023-09-30T18:54:42.224318Z","iopub.status.idle":"2023-09-30T18:54:46.585930Z","shell.execute_reply.started":"2023-09-30T18:54:42.224292Z","shell.execute_reply":"2023-09-30T18:54:46.584914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inference \n\n#Load model and move to GPU\nmodel = pipeline('text-generation', model=\"/kaggle/working/finetuned_gpt2\", device=\"cuda:0\")\n\n#Generate text and show results\nresult = model(test_prompt, penalty_alpha=0.7, top_k=5, max_new_tokens=300)\n\nprint(result[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:54:53.119304Z","iopub.execute_input":"2023-09-30T18:54:53.119685Z","iopub.status.idle":"2023-09-30T18:54:58.230827Z","shell.execute_reply.started":"2023-09-30T18:54:53.119655Z","shell.execute_reply":"2023-09-30T18:54:58.229849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}