{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T23:59:08.377351Z","iopub.execute_input":"2023-10-01T23:59:08.378376Z","iopub.status.idle":"2023-10-01T23:59:08.385194Z","shell.execute_reply.started":"2023-10-01T23:59:08.378307Z","shell.execute_reply":"2023-10-01T23:59:08.384084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install diffusers\n!pip install wandb\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:08.488283Z","iopub.execute_input":"2023-10-01T23:59:08.488979Z","iopub.status.idle":"2023-10-01T23:59:33.646367Z","shell.execute_reply.started":"2023-10-01T23:59:08.488949Z","shell.execute_reply":"2023-10-01T23:59:33.644785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load finetuned model ","metadata":{}},{"cell_type":"code","source":"import wandb\nimport torch\nimport logging\nfrom diffusers import StableDiffusionPipeline\nfrom transformers import (AutoTokenizer, AutoModelForCausalLM,\n                          DataCollatorForLanguageModeling, pipeline)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:33.649133Z","iopub.execute_input":"2023-10-01T23:59:33.649745Z","iopub.status.idle":"2023-10-01T23:59:33.658355Z","shell.execute_reply.started":"2023-10-01T23:59:33.649706Z","shell.execute_reply":"2023-10-01T23:59:33.657243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\n\n# Create a custom logger\nlogger = logging.getLogger(__name__)\n\n# Create handlers\nc_handler = logging.StreamHandler()\nc_handler.setLevel(logging.INFO)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:33.661910Z","iopub.execute_input":"2023-10-01T23:59:33.662425Z","iopub.status.idle":"2023-10-01T23:59:33.680227Z","shell.execute_reply.started":"2023-10-01T23:59:33.662393Z","shell.execute_reply":"2023-10-01T23:59:33.678792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variables\nPROJECT_ID = 'jbarata1998/song-generator/model-baseline_gpt2_finetune:v0'\nMODEL_ID_TEXT_GEN = \"gpt2\"\nMODEL_ID_SUMMARIZE = \"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:33.687244Z","iopub.execute_input":"2023-10-01T23:59:33.687548Z","iopub.status.idle":"2023-10-01T23:59:33.695232Z","shell.execute_reply.started":"2023-10-01T23:59:33.687525Z","shell.execute_reply":"2023-10-01T23:59:33.694073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download model artifact from wandb\nrun = wandb.init()\nartifact = run.use_artifact(PROJECT_ID, type='model')\nartifact_dir = artifact.download()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:59:33.699498Z","iopub.execute_input":"2023-10-01T23:59:33.700593Z","iopub.status.idle":"2023-10-02T00:00:13.381622Z","shell.execute_reply.started":"2023-10-01T23:59:33.700557Z","shell.execute_reply":"2023-10-02T00:00:13.380684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# init tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID_TEXT_GEN)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:00:13.382621Z","iopub.execute_input":"2023-10-02T00:00:13.382944Z","iopub.status.idle":"2023-10-02T00:00:13.896696Z","shell.execute_reply.started":"2023-10-02T00:00:13.382913Z","shell.execute_reply":"2023-10-02T00:00:13.895605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save tokenizer to load pipeline\ntokenizer.save_pretrained(artifact_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:00:13.901061Z","iopub.execute_input":"2023-10-02T00:00:13.903487Z","iopub.status.idle":"2023-10-02T00:00:14.182064Z","shell.execute_reply.started":"2023-10-02T00:00:13.903451Z","shell.execute_reply":"2023-10-02T00:00:14.181046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Album cover","metadata":{}},{"cell_type":"code","source":"class CoverGenerator:\n    def __init__(self, gen_model: str, summarize_model: str, diffuse_model: str):\n        self.gen_model = gen_model\n        self.summarize_model = summarize_model\n        self.diffuse_model = diffuse_model\n        \n    def gen_text(self, prompt: str, **kwargs: dict):\n        generator = pipeline('text-generation', model=self.gen_model)\n        result = generator(prompt, top_k=kwargs.get(\"top_k\", 5), max_new_tokens=kwargs.get(\"max_new_tokens\", 400))\n        self.song = result[0][\"generated_text\"]\n        print(f\"PROMPT: {prompt} \\n\\n SONG: \\n\\n {self.song}\")\n    \n    def summarize_text(self, **kwargs: dict):\n        try:\n            summarizer = pipeline(\"summarization\", self.summarize_model)\n            summary = summarizer(self.song, min_length=kwargs.get(\"min_length\", 5), max_length=kwargs.get(\"max_length\", 75))\n            self.song_summary = summary[0][\"summary_text\"]\n            print(f\" SUMMARY: \\n\\n {self.song_summary}\")\n        except Exception as e:\n            print(f\"Exception {e} occurred\")\n        \n    def gen_cover(self, **kwargs: dict):\n        pipe = StableDiffusionPipeline.from_pretrained(self.diffuse_model, torch_dtype=torch.float16)\n        pipe = pipe.to(\"cuda\")\n        image = pipe(self.song_summary).images[0]\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:06:23.371727Z","iopub.execute_input":"2023-10-02T00:06:23.372092Z","iopub.status.idle":"2023-10-02T00:06:23.380523Z","shell.execute_reply.started":"2023-10-02T00:06:23.372061Z","shell.execute_reply":"2023-10-02T00:06:23.379412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prompt = \"Well, good for you, I guess you moved on really easily\\nYou found a new girl and it only took a couple weeks\\nRemember when you said that you wanted to give me the world?\"\n\ncover_generator = CoverGenerator(gen_model = artifact_dir, summarize_model = \"facebook/bart-large-cnn\", diffuse_model = \"runwayml/stable-diffusion-v1-5\" )","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:06:24.020420Z","iopub.execute_input":"2023-10-02T00:06:24.020902Z","iopub.status.idle":"2023-10-02T00:06:24.030507Z","shell.execute_reply.started":"2023-10-02T00:06:24.020858Z","shell.execute_reply":"2023-10-02T00:06:24.029224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cover_generator.gen_text(prompt = test_prompt, top_k = 5, max_new_tokens = 400)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:06:26.415626Z","iopub.execute_input":"2023-10-02T00:06:26.415991Z","iopub.status.idle":"2023-10-02T00:06:54.748808Z","shell.execute_reply.started":"2023-10-02T00:06:26.415963Z","shell.execute_reply":"2023-10-02T00:06:54.747776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cover_generator.summarize_text(min_length= 5, max_length= 75, height=256, width=256)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:06:54.751119Z","iopub.execute_input":"2023-10-02T00:06:54.752202Z","iopub.status.idle":"2023-10-02T00:10:27.246140Z","shell.execute_reply.started":"2023-10-02T00:06:54.752053Z","shell.execute_reply":"2023-10-02T00:10:27.245013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cover_generator.gen_cover()\nimage","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:10:27.248158Z","iopub.execute_input":"2023-10-02T00:10:27.248906Z","iopub.status.idle":"2023-10-02T00:13:22.278585Z","shell.execute_reply.started":"2023-10-02T00:10:27.248867Z","shell.execute_reply":"2023-10-02T00:13:22.277706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
